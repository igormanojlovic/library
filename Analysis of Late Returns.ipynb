{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analysis Sample Instructions\n",
    "\n",
    "## Data Scientist\n",
    "\n",
    "### Data Science and Storytelling\n",
    "\n",
    "#### Overview\n",
    "\n",
    "**The Background Story**\n",
    "\n",
    "We are being hired by a local library with a problem: their books are being checked out and then returned late way too often. They would love to understand the cause of the issue and what they can learn from the data to proactively monitor the situation going forward.\n",
    "\n",
    "**The Mission**\n",
    "\n",
    "(Should you choose to accept)\n",
    "\n",
    "We'd like you to analyze the library data located [here](https://drive.google.com/drive/folders/12Rx8fqey6TSvBhg-CsgB0mDq6mQStSo5?usp=sharing) and help us build a model to predict the likelihood of a late return of any book at checkout time. Are there any factors you can find that are connected with late returns? What would you recommend the library do to mitigate the risks you find? How would you present your findings to them to get buy-in? The data has the following schema, with each table represented by one CSV file with the matching name.\n",
    "\n",
    "Good luck and happy analyzing!\n",
    "\n",
    "## Data Analyst\n",
    "\n",
    "### Requirements\n",
    "\n",
    "**Before Starting...**\n",
    "\n",
    "- Take a moment to think about how long you think this will take to get done.\n",
    "- Send an email to the address in the footer of this document with your estimated completion time.\n",
    "\n",
    "**Submitting Your Work**\n",
    "\n",
    "- Post your full source code/notebook to a public repo on GitHub or your preferred source control website.\n",
    "- Send an email to the address in the footer of this document with a link to the repository.\n",
    "\n",
    "**General**\n",
    "\n",
    "- Use R or Python for the analysis.\n",
    "- Include credits in your source for any resources pulled from the internet (if applicable).\n",
    "- Books are considered late if they are not returned within 28 days of checkout.\n",
    "- Please don’t share the data or include it in your repo.\n",
    "\n",
    "**Hints**\n",
    "\n",
    "- Ask questions to clarify as needed.\n",
    "- Answer the business questions posed above.\n",
    "- Ensure that your notebook is a good representation of your style.\n",
    "- Clearly document your thought process and any conclusions you reach.\n",
    "\n",
    "**Bonus**\n",
    "\n",
    "- Do something fun or creative with your analysis!\n",
    "- What other stories can you tell with this data?\n",
    "- Compare multiple models and showcase their strengths and weaknesses.\n"
   ],
   "id": "affb9ecae01e7e5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Proposed Solution\n",
    "\n",
    "This section provides the proposed solution to the presented problem. \n",
    "\n",
    "IMPORTANT: Please export the folder with CSV files to the parent directory."
   ],
   "id": "83e1c97c837e8852"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "Installing and importing necessary packages."
   ],
   "id": "87dc63dd87c69d6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install numpy pandas plotly scikit-learn xgboost kneed",
   "id": "3d9b21908122684c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "from kneed import KneeLocator\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ],
   "id": "fd87a91d671f274b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "max_checkout_days = 28",
   "id": "9859fb3f87924bd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Exploration\n",
    "\n",
    "Loading data from CSVs to pandas data frames."
   ],
   "id": "2c36992f1d0f801"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Books\n",
   "id": "e1fd37402cd75bb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_books = pd.read_csv('Data Challenge/books.csv')\n",
    "df_books"
   ],
   "id": "9ff84d63029aeb69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Customers",
   "id": "f3ec8a4310633bc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_customers = pd.read_csv('Data Challenge/customers.csv')\n",
    "df_customers"
   ],
   "id": "4249d14246ea9d75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Libraries\n",
   "id": "7048540e8170b9c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_libraries = pd.read_csv('Data Challenge/libraries.csv')\n",
    "df_libraries"
   ],
   "id": "dfefe1c5b70bde2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checkouts\n",
   "id": "7786dccffee9fb5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_checkouts = pd.read_csv('Data Challenge/checkouts.csv')\n",
    "df_checkouts"
   ],
   "id": "ccdc1ccacbd1d2ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Preparing features for building ML models."
   ],
   "id": "e120e1dcc8301ecf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Parsing\n",
    "\n",
    "Parsing dates and floats. The formats were obtained by analyzing values with ChatGPT. "
   ],
   "id": "c01106f8851b578d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def parse_date(date):\n",
    "    formats = [\n",
    "        '%Y',            # Year only\n",
    "        '%Y-%m-%d',      # Standard ISO format\n",
    "        '%Y/%m/%d',      # ISO format with slashes\n",
    "        '%Y.%m.%d',      # ISO format with dots\n",
    "        '%Y%m%d',        # Compact format without separators\n",
    "        '%d%m%Y',        # Compact format with day first\n",
    "        '%d%m%y',        # Compact format with short year\n",
    "        '%d-%m-%Y',      # Day first with dashes\n",
    "        '%d/%m/%Y',      # Day first with slashes\n",
    "        '%d.%m.%Y',      # Day first with dots\n",
    "        '%d %m %Y',      # Day with spaces\n",
    "        '%Y %b %d',      # Year with abbreviated month\n",
    "        '%d %B %Y',      # Day with full month name\n",
    "        '%d %b %Y',      # Day with abbreviated month\n",
    "        '%Y|%m|%d',      # Custom format with pipes\n",
    "        '%Y-%m-%d%',     # ISO format with trailing percent sign\n",
    "        '%y-%m-%d',      # Short year format\n",
    "        '%y%m%d'         # Short year compact format\n",
    "    ]\n",
    "    \n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return datetime.strptime(str(date), fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return pd.NaT\n",
    "\n",
    "\n",
    "df_books['price'] = df_books['price'].replace({'[*,$,USD,|]': ''}, regex=True).astype(float)\n",
    "df_books['pages'] = df_books['pages'].replace({'[*,|,^,#]': ''}, regex=True).astype(float)\n",
    "df_books['publishedDate'] = df_books['publishedDate'].apply(parse_date)\n",
    "df_customers['birth_date'] = df_customers['birth_date'].apply(parse_date)\n",
    "df_checkouts['date_checkout'] = df_checkouts['date_checkout'].apply(parse_date)\n",
    "df_checkouts['date_returned'] = df_checkouts['date_returned'].apply(parse_date)"
   ],
   "id": "5d66f66d8dbaca8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Merging\n",
    "\n",
    "Merging books, customers, libraries, and checkouts into one data frame for further analysis."
   ],
   "id": "f428bf54d2cb1d61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_merged = pd.merge(df_checkouts, df_books.rename(columns={c: f'book_{c}' for c in df_books.columns}), left_on='id', right_on='book_id')\n",
    "df_merged = pd.merge(df_merged, df_customers.rename(columns={c: f'customer_{c}' for c in df_customers.columns}), left_on='patron_id', right_on='customer_id')\n",
    "df_merged = pd.merge(df_merged, df_libraries.rename(columns={c: f'library_{c}' for c in df_libraries.columns}), left_on='library_id', right_on='library_id')\n",
    "df_merged"
   ],
   "id": "643c3c8b56e558a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Featurization\n",
    "\n",
    "Preparing features that an ML model can learn from as follows:\n",
    "1. Selecting float values, such as book price and pages.\n",
    "2. Selecting categorical features with not too high and not too low cardinality of distinct values, and transforming them into binary choices. \n",
    "3. Extending the feature set with date differences, such as the age of customers and books. \n",
    "4. Marking the late returns by calculating the difference between the checkout and returned date. "
   ],
   "id": "52906d99fca19031"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def unique_category(category):\n",
    "    return str(category).lower().strip().replace(\"  \", \"\")\n",
    "    \n",
    "    \n",
    "def one_hot_encode(df, column):\n",
    "    if column not in df.columns:\n",
    "        return df\n",
    "    \n",
    "    df_encoded = pd.get_dummies(df[column].apply(unique_category)).astype(int)\n",
    "    df_encoded.columns = [f'{column} - {_}' for _ in df_encoded.columns]\n",
    "    df = pd.merge(df, df_encoded, left_index=True, right_index=True)\n",
    "    df.drop(columns=[column], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def multi_hot_encode(df, column):\n",
    "    if column not in df.columns:\n",
    "        return df\n",
    "    \n",
    "    df_exploded = df[column].apply(lambda _: ast.literal_eval(_) if pd.notna(_) else _).explode()\n",
    "    df_encoded = pd.get_dummies(df_exploded.apply(unique_category))\n",
    "    df_encoded = df_encoded.groupby(df_encoded.index).sum()\n",
    "    df_encoded.columns = [f'{column} - {_}' for _ in df_encoded.columns]\n",
    "    df_result = pd.merge(df, df_encoded, left_index=True, right_index=True)\n",
    "    df_result.drop(columns=[column], inplace=True)\n",
    "    return df_result\n",
    "\n",
    "\n",
    "df_xy = pd.DataFrame(df_merged[[\n",
    "    'date_checkout',\n",
    "    'date_returned',\n",
    "    'book_authors', \n",
    "    'book_categories',\n",
    "    'book_publishedDate',\n",
    "    'book_price',\n",
    "    'book_pages',\n",
    "    'customer_birth_date',\n",
    "    'customer_gender',\n",
    "    'customer_education',\n",
    "    'customer_occupation',\n",
    "    'library_name',\n",
    "]])\n",
    "\n",
    "df_xy = df_xy[(datetime(2000, 1, 1) < df_xy['date_checkout']) & (df_xy['date_checkout'] < datetime.now())] # Selecting valid dates.\n",
    "df_xy['checkout_days'] = (df_xy['date_returned'] - df_xy['date_checkout']).dt.days # For returned books.\n",
    "df_xy.loc[df_xy['date_returned'].isna(), 'checkout_days'] = (datetime.now() - df_xy['date_checkout']).dt.days # For not yet returned books.\n",
    "df_xy = df_xy[~((df_xy['date_returned'].isna()) & (df_xy['checkout_days'] <= 28))] # Removing rows where the book can be returned on time.\n",
    "df_xy = df_xy[df_xy['checkout_days']>0] # Removing rows where the number of checkout days is negative.\n",
    "df_xy['late_return'] = (df_xy['checkout_days'] > max_checkout_days).astype(int) # Whether the book was not returned on time.\n",
    "df_xy['customer_age'] = (datetime.now() - df_xy['customer_birth_date']).dt.days / 365 # Transforming birth date to age.\n",
    "df_xy['book_age'] = (datetime.now() - df_xy['book_publishedDate']).dt.days / 365 # Transforming published date to age.\n",
    "df_xy.drop(columns=['date_returned', 'customer_birth_date', 'book_publishedDate'], inplace=True)\n",
    "df_xy = multi_hot_encode(df_xy, 'book_authors')\n",
    "df_xy = multi_hot_encode(df_xy, 'book_categories')\n",
    "df_xy = one_hot_encode(df_xy, 'customer_gender')\n",
    "df_xy = one_hot_encode(df_xy, 'customer_education')\n",
    "df_xy = one_hot_encode(df_xy, 'customer_occupation')\n",
    "df_xy = one_hot_encode(df_xy, 'library_name')\n",
    "df_xy.drop(columns=[_ for _ in df_xy.columns if _.endswith(' - nan') or _.endswith(' - others')], inplace=True) # Drop undefined categories.\n",
    "df_xy.drop(columns=[_ for _ in df_xy.columns if len(df_xy[_].unique()) == 1], inplace=True) # Drop constants.\n",
    "df_xy.dropna(inplace=True)\n",
    "df_xy"
   ],
   "id": "949b686f6721b6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Analysis",
   "id": "72bb67f71fc6d666"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Correlation Analysis\n",
    "\n",
    "The following plot shows Spearman correlation of the feature values with the late returns. For simplicity, the categorical feature values that were previously transformed into binary choices are grouped by category names so that the plot shows only the minimum and maximum for each group. For the features that were not transformed in this way the plot shows the same minimum and maximum. \n",
    "\n",
    "The results show that the correlation is weak in all the cases, indicating that there is a need for exploring alternatives, such as incorporating features like holidays, weather, or local events that might influence book returns."
   ],
   "id": "36d2d6575bd20d24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_features(df, name_col, value_col):\n",
    "    df_result = pd.DataFrame(df[[name_col, value_col]])\n",
    "    df_result.columns=['feature', 'value']\n",
    "    df_result['feature'] = df_result['feature'].apply(lambda _: _.split(' - ')[0])\n",
    "    df_result = df_result.groupby('feature', sort=False).aggregate(['min', 'max']).reset_index()\n",
    "    df_result.columns = ['feature', 'min', 'max']\n",
    "    fig = px.bar(df_result, x='feature', y=['min', 'max'], barmode='group')\n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "def plot_corr(df, target, method='spearman'):\n",
    "    df_corr = df.corr(method)[target].reset_index()\n",
    "    df_corr = df_corr[df_corr['index'] != target]\n",
    "    df_corr.sort_values(target, ascending=False, inplace=True)\n",
    "    plot_features(df_corr, 'index', target)\n",
    "\n",
    "\n",
    "plot_corr(df_xy.drop(columns=['date_checkout', 'checkout_days']), 'late_return')"
   ],
   "id": "c46ba7fde603960",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Trend Analysis\n",
    "\n",
    "The following plot shows the number of late returns for different checkout dates. The periodic fluctuations of the presented values over time imply that the calendar features, such as day of the week, month of the year, etc., could be useful for predicting the late returns.\n",
    "\n"
   ],
   "id": "992991410bfcf9ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "px.line(df_xy.groupby('date_checkout').sum('late_return').reset_index(), x='date_checkout', y='late_return')",
   "id": "a2bb0bd50ed4bb30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Augmentation",
   "id": "6359523f2009f588"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Time Encoders\n",
    "\n",
    "Preparing classes for encoding calendar features like clock positions (2D Cartesian coordinates on a unit circle). This kind of encoding preserves both the distance and periodicity of the feature values in Euclidean space, in contrast to one-hot encoding for example."
   ],
   "id": "46d622585b353693"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TimeEncoder:\n",
    "    def __init__(self, *features: str):\n",
    "        \"\"\"\n",
    "        Abstract time feature encoder.\n",
    "\n",
    "        :param features: Feature names that will be used to create named tuples.\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "\n",
    "    def encode(self, t: pd.Timestamp) -> pd.DataFrame:\n",
    "        pass\n",
    "\n",
    "    def __call__(self, t: pd.Timestamp):\n",
    "        \"\"\"Transforms the specified timestamp into numeric values.\"\"\"\n",
    "        return self.encode(t)\n",
    "\n",
    "\n",
    "class PeriodicTimeEncoder(TimeEncoder):\n",
    "    def __init__(self):\n",
    "        t = type(self).__name__\n",
    "        super().__init__(f'{t}X', f'{t}Y')\n",
    "\n",
    "    def length(self) -> int:\n",
    "        \"\"\"Returns the cycle length.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def index(self, t: pd.Series) -> pd.Series:\n",
    "        \"\"\"Extracts the index of the timestamp position on the cycle.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def encode(self, t: pd.Series) -> pd.DataFrame:\n",
    "        clock_position = 2 * np.pi * self.index(t) / self.length()\n",
    "        return pd.DataFrame({\n",
    "            f'{type(self).__name__} - X': (np.sin(clock_position)+1)/2, \n",
    "            f'{type(self).__name__} - Y': (np.cos(clock_position)+1)/2\n",
    "        })\n",
    "\n",
    "\n",
    "class MonthOfYear(PeriodicTimeEncoder):\n",
    "    \"\"\"Encodes month of year as 2D Cartesian coordinates on a unit circle (clock positions).\"\"\"\n",
    "\n",
    "    def length(self) -> int:\n",
    "        return 12\n",
    "\n",
    "    def index(self, t: pd.Series) -> pd.Series:\n",
    "        return t.dt.month - 1\n",
    "\n",
    "\n",
    "class DayOfMonth(PeriodicTimeEncoder):\n",
    "    \"\"\"Encodes week of year as 2D Cartesian coordinates on a unit circle (clock positions).\"\"\"\n",
    "\n",
    "    def length(self) -> int:\n",
    "        return 31\n",
    "\n",
    "    def index(self, t: pd.Series) -> pd.Series:\n",
    "        return t.dt.day - 1\n",
    "\n",
    "\n",
    "class DayOfWeek(PeriodicTimeEncoder):\n",
    "    \"\"\"Encodes day of week as 2D Cartesian coordinates on a unit circle (clock positions).\"\"\"\n",
    "\n",
    "    def length(self) -> int:\n",
    "        return 7\n",
    "\n",
    "    def index(self, t: pd.Series) -> pd.Series:\n",
    "        return t.dt.dayofweek - 1\n",
    "\n",
    "  \n",
    "class TimeEncoders(TimeEncoder):\n",
    "    def __init__(self, *encoders: TimeEncoder):\n",
    "        \"\"\"Encodes multiple time features using the specified time encoders.\"\"\"\n",
    "        super().__init__(*list(chain.from_iterable([_.features for _ in encoders])))\n",
    "        self.encoders = encoders\n",
    "\n",
    "    def encode(self, t: pd.Timestamp) -> pd.DataFrame:\n",
    "        return pd.concat([_.encode(t) for _ in self.encoders], axis=1)"
   ],
   "id": "5305965245e5779",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Time Encoding\n",
    "Encoding month of year, day of month, and day of week like clock positions."
   ],
   "id": "d89ff3796fe819ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "time_encoders = TimeEncoders(MonthOfYear(), DayOfMonth(), DayOfWeek())#%% md\n",
    "df_encoded_time = time_encoders(df_xy['date_checkout'])\n",
    "df_xy = pd.concat((df_xy, df_encoded_time), axis=1)\n",
    "df_xy"
   ],
   "id": "b6209f526a5f100b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Correlation Analysis With New Features\n",
    "\n",
    "The following plot shows that the newly added features (month of year, day of month, and day of week) could be useful for predicting the late returns, compared with the other features."
   ],
   "id": "95a4890b241fcf88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_corr(df_xy.drop(columns=['date_checkout', 'checkout_days']), 'late_return')",
   "id": "6640a9fb6c4c8f70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model Selection\n",
    "\n",
    "Evaluating traditional (shallow learning) classifiers: logistic regression, decision tree, random forest, extreme gradient boosting, and support vector machines. For simplicity, the classifiers are used with default hyperparameters and evaluated with commonly used classification metrics utilizing cross validation. \n",
    "\n",
    "NOTE: The evaluation process can be extended to include hyperparameter optimization and other models."
   ],
   "id": "1b8f27a7c4af2030"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data Splitting and Scaling\n",
    "\n",
    "Preparing scaled features (x), targets (y), and weights (w)."
   ],
   "id": "e8918063642dd213"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_x = df_xy.drop(columns=['date_checkout', 'checkout_days', 'late_return'])\n",
    "x = MinMaxScaler().fit_transform(df_x.values)\n",
    "y = df_xy['late_return'].values\n",
    "w = df_xy['checkout_days'].values / max_checkout_days # Weights for handling imbalance in late returns. "
   ],
   "id": "f405c3d2930ae4e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Cross Validation\n",
    "\n",
    "Evaluating classification models with 5-fold cross validation using the following metrics:\n",
    "1. Accuracy\n",
    "2. Precision\n",
    "3. Recall\n",
    "4. F1 Score \n",
    "5. ROC AUC (Receiver Operating Characteristic - Area Under the Curve)\n",
    "6. Balanced Accuracy\n",
    "7. Average Precision\n",
    "8. Matthews Correlation Coefficient (MCC)\n",
    "\n",
    "The following descriptions were generated by ChatGPT.\n",
    "\n",
    "#### 1. Accuracy\n",
    "**Definition:** The ratio of correctly predicted instances (both true positives and true negatives) to the total number of instances.  \n",
    "**Formula:**  \n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{True Positives} + \\text{True Negatives}}{\\text{Total Instances}}\n",
    "$$  \n",
    "**Range:** [0, 1]  \n",
    "**Interpretation:**\n",
    "- **0:** No correct predictions (worst case).\n",
    "- **1:** All predictions are correct (best case).\n",
    "- **Usefulness:** Accuracy is a useful general measure, but it can be misleading in cases of imbalanced datasets where the majority class dominates.\n",
    "\n",
    "#### 2. Precision\n",
    "**Definition:** The ratio of correctly predicted positive instances (true positives) to the total predicted positives (true positives + false positives).  \n",
    "**Formula:**  \n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\n",
    "$$  \n",
    "**Range:** [0, 1]  \n",
    "**Interpretation:**\n",
    "- **0:** No true positives, only false positives (worst case).\n",
    "- **1:** All predicted positives are true positives, no false positives (best case).\n",
    "- **Usefulness:** Precision is crucial when the cost of false positives is high (e.g., in spam detection).\n",
    "\n",
    "#### 3. Recall\n",
    "**Definition:** The ratio of correctly predicted positive instances to the total actual positives (true positives + false negatives).  \n",
    "**Formula:**  \n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n",
    "$$  \n",
    "**Range:** [0, 1]  \n",
    "**Interpretation:**\n",
    "- **0:** No true positives are captured; all actual positives are missed (worst case).\n",
    "- **1:** All actual positives are captured by the model (best case).\n",
    "- **Usefulness:** Recall is important when the cost of false negatives is high (e.g., in medical diagnostics).\n",
    "\n",
    "#### 4. F1 Score\n",
    "**Definition:** The harmonic mean of precision and recall.  \n",
    "**Formula:**  \n",
    "$$\n",
    "\\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$  \n",
    "**Range:** [0, 1]  \n",
    "**Interpretation:**\n",
    "- **0:** Either precision or recall (or both) is zero (worst case).\n",
    "- **1:** Both precision and recall are perfect (best case).\n",
    "- **Usefulness:** The F1 Score is useful when you need to balance precision and recall, especially in imbalanced datasets.\n",
    "\n",
    "#### 5. ROC AUC (Receiver Operating Characteristic - Area Under the Curve)\n",
    "**Definition:** AUC measures the area under the ROC curve, which plots the true positive rate against the false positive rate at various threshold settings.  \n",
    "**Range:** [0, 1]  \n",
    "**Interpretation:**\n",
    "- **0.5:** The model performs no better than random guessing.\n",
    "- **1:** The model perfectly distinguishes between the classes.\n",
    "- **Usefulness:** ROC AUC is useful to evaluate the model’s ability to distinguish between the positive and negative classes across all threshold values.\n",
    "\n",
    "#### 6. Balanced Accuracy\n",
    "**Definition:** The average of recall obtained on each class, particularly useful for imbalanced datasets.  \n",
    "**Formula:**  \n",
    "$$\n",
    "\\text{Balanced Accuracy} = \\frac{1}{2} \\left( \\frac{\\text{True Positives}}{\\text{Actual Positives}} + \\frac{\\text{True Negatives}}{\\text{Actual Negatives}} \\right)\n",
    "$$  \n",
    "**Range:** [0, 1]  \n",
    "**Interpretation:**\n",
    "- **0:** The model performs as badly as possible on both classes.\n",
    "- **1:** The model perfectly predicts both classes.\n",
    "- **Usefulness:** Balanced accuracy gives a more truthful measure of performance for imbalanced datasets by equally weighing the accuracy of each class.\n",
    "\n",
    "#### 7. Average Precision\n",
    "**Definition:** The average of precision scores calculated at different thresholds, weighted by the increase in recall from the previous threshold.  \n",
    "**Range:** [0, 1]  \n",
    "**Interpretation:**\n",
    "- **0:** No precision; the model predicts only false positives.\n",
    "- **1:** Perfect precision at all thresholds.\n",
    "- **Usefulness:** Average precision provides a single-number summary of the precision-recall curve, useful in cases with imbalanced classes.\n",
    "\n",
    "#### 8. Matthews Correlation Coefficient (MCC)\n",
    "**Definition:** MCC is a measure of the quality of binary classifications, considering all four confusion matrix categories (true positives, false positives, true negatives, and false negatives).  \n",
    "**Formula:**  \n",
    "$$\n",
    "\\text{MCC} = \\frac{(\\text{True Positives} \\times \\text{True Negatives}) - (\\text{False Positives} \\times \\text{False Negatives})}{\\sqrt{(\\text{True Positives} + \\text{False Positives}) \\times (\\text{True Positives} + \\text{False Negatives}) \\times (\\text{True Negatives} + \\text{False Positives}) \\times (\\text{True Negatives} + \\text{False Negatives})}}\n",
    "$$  \n",
    "**Range:** [-1, 1]  \n",
    "**Interpretation:**\n",
    "- **-1:** Total disagreement between predicted and actual values.\n",
    "- **0:** Predictions are no better than random.\n",
    "- **1:** Perfect prediction.\n",
    "- **Usefulness:** MCC is a balanced metric even for imbalanced classes, providing a comprehensive view of prediction performance.\n"
   ],
   "id": "aeda4c41177c6991"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_classifier(c, x_samples, y_samples, w_samples):\n",
    "    scoring = {\n",
    "        'Accuracy': 'accuracy',\n",
    "        'Precision': 'precision',\n",
    "        'Recall': 'recall',\n",
    "        'F1': 'f1',\n",
    "        'ROC_AUC': 'roc_auc',\n",
    "        'Balanced_Accuracy': 'balanced_accuracy',\n",
    "        'Average_Precision': 'average_precision',\n",
    "        'MCC': 'matthews_corrcoef',\n",
    "    }\n",
    "    \n",
    "    scores = cross_validate(c, x_samples, y_samples, params={'sample_weight': w_samples}, cv=5, scoring=scoring, return_train_score=True)\n",
    "    df_result = pd.DataFrame(scores).reset_index()\n",
    "    df_result.rename(columns={'index': 'partition'}, inplace=True)\n",
    "    df_result['classifier'] = type(c).__name__.replace('Classifier', '')\n",
    "    return df_result\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    XGBClassifier(),\n",
    "    SVC(kernel='linear',probability=True)\n",
    "]\n",
    "  \n",
    "df_scores = pd.concat([evaluate_classifier(_, x, y, w) for _ in classifiers])\n",
    "df_scores.drop(columns=['partition']).groupby('classifier', sort=False).mean().T"
   ],
   "id": "8114ff6339928d77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Reducing Overfitting\n",
    "\n",
    "The winner is the XGB model, which has the best balance between the accuracy metrics, especially F1 score and ROC-AUC. However, the significant difference in accuracy on training and test sets implies overfitting. Simple approaches to reducing overfitting include the model simplification (e.g., by reducing max depth) and feature selection (e.g., by selecting the features above the elbow of the curve defined by feature importance). The following table shows that these approaches indeed reduce overfitting but also the accuracy, implying that more data could help the model generalize better."
   ],
   "id": "2a21af53c4310702"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xgb_importance = XGBClassifier().fit(x, y, sample_weight=w).feature_importances_\n",
    "df_xgb_importance = pd.DataFrame({'feature': df_x.columns, 'importance': xgb_importance})\n",
    "df_xgb_importance.sort_values('importance', ascending=False, inplace=True)\n",
    "elbow = KneeLocator(range(len(df_xgb_importance)), df_xgb_importance.importance, curve='convex', direction='decreasing').knee\n",
    "df_x_reduced = df_xy[df_xgb_importance[:elbow].feature]\n",
    "x_reduced = df_x_reduced.values\n",
    "\n",
    "df_xgb_scores = evaluate_classifier(XGBClassifier(max_depth=4), x_reduced, y, w)\n",
    "df_xgb_scores.drop(columns=['partition', 'classifier']).mean().T"
   ],
   "id": "7f3191f3dc79c659",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### The Winner\n",
    "\n",
    "Retraining the winner model with all the data points and showing the feature importance. "
   ],
   "id": "883cc07abd6b9da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "winner = XGBClassifier(max_depth=4).fit(x_reduced, y, sample_weight=w)",
   "id": "e8a9ab162e08c4d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Feature Importance\n",
    "\n",
    "For simplicity, the categorical feature values that were previously transformed into binary choices are grouped by category names so that the plot shows only the minimum and maximum for each group. For the features that were not transformed in this way the plot shows the same minimum and maximum."
   ],
   "id": "8900e572aff986f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_winner_importance = pd.DataFrame({'feature': df_x_reduced.columns, 'importance': winner.feature_importances_})\n",
    "df_winner_importance.sort_values('importance', ascending=False, inplace=True)\n",
    "plot_features(df_winner_importance, 'feature', 'importance')"
   ],
   "id": "9a306bc7616dacfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Top 10 Most Important Features",
   "id": "40d09967dc1b32b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "px.bar(df_winner_importance[:10], x='feature', y='importance')",
   "id": "14e1e7cef28eff8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Final Result\n",
    "\n",
    "The final result obtained from the winner model - the likelihood that a book will be returned late, presented in the form of histogram. "
   ],
   "id": "d6c81e6b59ddb12b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "p = winner.predict_proba(x_reduced)[:,1]\n",
    "px.histogram(pd.DataFrame({'Likelihood of a Late Return': p}))"
   ],
   "id": "f6ef051fdc749849",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Recommendations\n",
    "\n",
    "The following strategies could be implemented based on the prepared model:\n",
    "1. Proactively identifying checkouts with higher likelihood of a late return and informing the customer.\n",
    "2. Providing more frequent reminders to customers for checkouts with higher likelihood of late returns."
   ],
   "id": "8bd922d6802c5cc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b9e89141e2886f2c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
